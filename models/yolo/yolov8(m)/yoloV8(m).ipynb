{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMX2taXSztL-"
      },
      "source": [
        "> **Note:** This notebook is intended to be run on **Google Colab**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfhC7eXYzvzP"
      },
      "source": [
        "### I. Load & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "XmIaCT1uzj6U",
        "outputId": "f945b018-9cb3-4672-e7b5-b1bc43dcbbcd"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXofrrx6z1qu",
        "outputId": "887f8122-892a-4929-8ab9-53928a36d036"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nrK7KDTz3rI",
        "outputId": "5eada593-5205-4099-c2f0-120985dfdbd6"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image\n",
        "from PIL import Image as PILImage\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp_qXmdu0NsI"
      },
      "source": [
        "### II. Dataset Extraction & Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6argTAM90QCy",
        "outputId": "68762b22-1767-4c34-b5b7-0800c95b74a2"
      },
      "outputs": [],
      "source": [
        "# path to the zip dataset\n",
        "zip_path = \"Tire Dataset.v2i.yolov8 (1).zip\"\n",
        "\n",
        "# directory where the dataset will be extracted\n",
        "extract_path = \"/content/dataset\"\n",
        "\n",
        "# create the directory if it does not exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# extract all files from the zip archive\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction terminée. Les fichiers ont été extraits dans :\", extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVSrAPyq0SWS",
        "outputId": "2d8db250-9f25-4d4b-fede-4be7baa8e527"
      },
      "outputs": [],
      "source": [
        "# rename the \"valid\" folder to \"val\"\n",
        "os.rename('/content/dataset/valid', '/content/dataset/val')\n",
        "\n",
        "# read the content of a label file\n",
        "with open('/content/dataset/train/labels/1001_png.rf.05300e4f0f2316063d99d0ca39a76ca6.txt') as f:\n",
        "    lines = f.readlines()\n",
        "    print(\"Contenu du fichier :\")\n",
        "    print(lines)\n",
        "\n",
        "# extract class IDs from the label file\n",
        "class_ids = [line.strip().split()[0] for line in lines]\n",
        "\n",
        "# list unique class IDs used\n",
        "unique_ids = sorted(set(class_ids))\n",
        "print(\"\\nClasses utilisées dans ce fichier :\", unique_ids)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sUFtfRdEPxP"
      },
      "source": [
        "### III. YAML Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEdZhDlZETgV"
      },
      "outputs": [],
      "source": [
        "# create and write the corrected YAML configuration file\n",
        "fixed_yaml = \"\"\"\n",
        "train: ../train/images\n",
        "val: ../val/images\n",
        "test: ../test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['car-tire']\n",
        "\n",
        "roboflow:\n",
        "  workspace: iotml\n",
        "  project: tire-dataset\n",
        "  version: 2\n",
        "  license: Public Domain\n",
        "  url: https://universe.roboflow.com/iotml/tire-dataset/dataset/2\n",
        "\"\"\"\n",
        "\n",
        "# save the YAML file to the dataset directory\n",
        "with open('/content/dataset/data.yaml', 'w') as f:\n",
        "    f.write(fixed_yaml)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1WkEdScEb7z"
      },
      "source": [
        "### IV. Model Training & Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyqFB-FJIKF2"
      },
      "source": [
        "### Explication du modèle et des paramètres d’entraînement\n",
        "\n",
        "Modèle utilisé : **YOLOv8m** - version intermédiaire de la famille YOLOv8, offrant un bon compromis entre vitesse et précision. \n",
        "Principaux paramètres: \n",
        "- Transfert d’apprentissage\n",
        "  - Chargement de poids pré-entraînés sur COCO\n",
        "  - Accélèration de la convergence et amélioration de la précision initiale\n",
        "\n",
        "- Automatic Mixed Precision (AMP)\n",
        "  - AMP combine des calculs en 16 bits et 32 bits\n",
        "  - Avantages : vitesse accrue et réduction de la mémoire GPU\n",
        "\n",
        "- Chargement des données\n",
        "  - Scan et mise en cache des images et labels\n",
        "  - Dataset utilisé :\n",
        "    - Train : 1461 images\n",
        "    - Validation : 190 images\n",
        "  - Résolution utilisée : 800×800 px, optimisée pour YOLOv8m (meilleure précision que 640×640)\n",
        "\n",
        "- Augmentations \n",
        "Transformations légères pour la robustesse du modèle :\n",
        "  - `Blur(p=0.01)`\n",
        "  - `MedianBlur(p=0.01)`\n",
        "  - `ToGray(p=0.01)`\n",
        "  - Amélioration de généralisation du modèle\n",
        "\n",
        "- Optimiseur (AdamW)\n",
        "  - Sélection automatique de  l’optimiseur\n",
        "  - Paramètres importants :\n",
        "    - `lr = 0.002`\n",
        "    - `momentum = 0.9`\n",
        "    - `weight_decay` activé (meilleure régularisation)\n",
        "  - Bon équilibre entre stabilité et généralisation\n",
        "\n",
        "- Chargement en parallèle\n",
        "  - Utilisation de 2 workers pour accélérer la préparation des batches\n",
        "\n",
        "- Début de l’entraînement\n",
        "Entraînement pendant 50 epochs et optimisation : \n",
        "  - box_loss – précision de la localisation\n",
        "  - cls_loss – classification des objets\n",
        "  - dfl_loss – Distribution Focal Loss (forme/uniformité des boîtes)\n",
        "\n",
        "Une diminution progressive de ces pertes indique un modèle qui apprend correctement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnesZaWKEhWr",
        "outputId": "fc080b94-4100-4e4e-d35a-844153b0f113"
      },
      "outputs": [],
      "source": [
        "# Load the YOLOv8 medium model\n",
        "model = YOLO(\"yolov8m.pt\")\n",
        "\n",
        "# Train the model using a larger image size (800px) to improve detection precision\n",
        "model.train(data=\"/content/dataset/data.yaml\", epochs=50, imgsz=800)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCiitxGRFmdc"
      },
      "source": [
        "### V. Visualization of Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xJuqmbzFVEE"
      },
      "outputs": [],
      "source": [
        "def display_img(path, width=800, title=None):\n",
        "    \"\"\"\n",
        "    Display a single image with optional resizing and custom title.\n",
        "    \"\"\"\n",
        "    img = PILImage.open(path)\n",
        "    img = img.resize((width, int(img.height * width / img.width)))  # keep aspect ratio\n",
        "\n",
        "    if title:\n",
        "        print(f\"{title}\")\n",
        "\n",
        "    display(img)\n",
        "\n",
        "\n",
        "def display_img_list(folder, files, width=800):\n",
        "    \"\"\"\n",
        "    Display a list of images from a given folder.\n",
        "    \"\"\"\n",
        "    for filename, title in files:\n",
        "        full_path = f\"{folder}/{filename}\"\n",
        "        display_img(full_path, width=width, title=title)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7MEiZA5SGKDv",
        "outputId": "4f35a86c-6fb9-4563-cc48-d2e381342573"
      },
      "outputs": [],
      "source": [
        "# List of training performance plots generated by YOLOv8.\n",
        "train_files = [\n",
        "    (\"results.png\", \"Training Metrics Overview\"),\n",
        "    (\"BoxPR_curve.png\", \"Box Precision-Recall Curve (Train)\"),\n",
        "    (\"BoxF1_curve.png\", \"Box F1-Confidence Curve (Train)\"),\n",
        "    (\"BoxP_curve.png\", \"Box Precision Curve (Train)\"),\n",
        "    (\"BoxR_curve.png\", \"Box Recall Curve (Train)\"),\n",
        "    (\"confusion_matrix.png\", \"Confusion Matrix (Train)\"),\n",
        "    (\"labels.jpg\", \"Label Distribution\"),\n",
        "]\n",
        "\n",
        "display_img_list(\"runs/detect/train\", train_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j921tpEdaZ7K"
      },
      "source": [
        "Le modèle présente d'excellentes performances.\n",
        "Les courbes d’évaluation montrent une précision et un rappel élevés, avec un score F1 optimal d’environ 0,91 atteint pour un seuil de confiance proche de 0,32.\n",
        "Les métriques mAP50 et mAP50-95 indiquent également une bonne qualité de localisation et de classification, confirmant la robustesse du modèle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3HPQsiYGXPP"
      },
      "source": [
        "### VI. Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQxzUU1gGbfG",
        "outputId": "2b862bfd-2020-4224-de99-e1c7825f3105"
      },
      "outputs": [],
      "source": [
        "# Load the trained YOLOv8 model using the best checkpoint from training\n",
        "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
        "\n",
        "# Evaluate the model on the test split defined in data.yaml\n",
        "metrics = model.val(data=\"/content/dataset/data.yaml\", split=\"test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f0PrHXdEGdpY",
        "outputId": "3772946b-d350-4a02-83fe-e46965a1ac5a"
      },
      "outputs": [],
      "source": [
        "# List of evaluation plots generated by YOLOv8 for the test dataset.\n",
        "test_files = [\n",
        "    (\"BoxF1_curve.png\", \"Box F1-Confidence Curve (Test)\"),\n",
        "    (\"BoxPR_curve.png\", \"Box Precision-Recall Curve (Test)\"),\n",
        "    (\"BoxP_curve.png\", \"Box Precision Curve (Test)\"),\n",
        "    (\"BoxR_curve.png\", \"Box Recall Curve (Test)\"),\n",
        "    (\"confusion_matrix.png\", \"Confusion Matrix (Test)\"),\n",
        "]\n",
        "\n",
        "display_img_list(\"runs/detect/val\", test_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55FSLIQhbZwM"
      },
      "source": [
        "Les métriques obtenues sur les 103 images du jeu de test montrent que le modèle réalise une détection très solide :\n",
        "- Précision : 0.914\n",
        "→ Très peu de faux positifs : lorsque le modèle détecte un pneu, il se trompe rarement.\n",
        "\n",
        "- Recall : 0.909\n",
        "→ Très bonne couverture des objets : le modèle détecte la majorité des pneus présents.\n",
        "\n",
        "- mAP@50 : 0.953\n",
        "→ Excellent taux de correspondance IoU ≥ 0.50 entre prédictions et annotations.\n",
        "\n",
        "- mAP@50–95 : 0.609\n",
        "→ Indique une performance correcte mais perfectible pour la localisation fine (IoU plus stricts).\n",
        "\n",
        "Ces résultats confirment la robustesse et la généralisation du modèle ( pas d'overfitting visible)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp9KtHt2bkAy"
      },
      "source": [
        "Rséultats du score F1:\n",
        "- Score F1 maximal ≈ 0.91 atteint à une confiance d’environ 0.14\n",
        "- Optimisation de l'équilibre par un seuil de confiance bas\n",
        "\n",
        "- Excellente stabilité de la courbe entre 0.1 et 0.6 : \n",
        "→ Le modèle reste performant dans une large plage de seuils de confiance.\n",
        "- Hausse des faux positifs en dessous de 0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xrx-tFKsGveA"
      },
      "source": [
        "### VII. Qualitative Evaluation (Visual Comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "CJmfbLLfGrOm",
        "outputId": "72f1a87d-1105-4cd9-f67e-807d4e36e962"
      },
      "outputs": [],
      "source": [
        "def display_side_by_side(img1_path, img2_path, label1=\"Ground Truth\", label2=\"Prediction\"):\n",
        "    \"\"\"\n",
        "    Display two images side by side for visual comparison.\n",
        "\n",
        "    Parameters:\n",
        "        img1_path (str): Path to the first image (typically ground-truth labels).\n",
        "        img2_path (str): Path to the second image (typically model predictions).\n",
        "        label1 (str): Title displayed above the first image.\n",
        "        label2 (str): Title displayed above the second image.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load both images\n",
        "    img1 = PILImage.open(img1_path)\n",
        "    img2 = PILImage.open(img2_path)\n",
        "\n",
        "    # Create a figure with two columns\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(14, 7))\n",
        "\n",
        "    # Left image (Ground Truth)\n",
        "    axs[0].imshow(img1)\n",
        "    axs[0].set_title(label1, fontsize=14)\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    # Right image (Prediction)\n",
        "    axs[1].imshow(img2)\n",
        "    axs[1].set_title(label2, fontsize=14)\n",
        "    axs[1].axis('off')\n",
        "\n",
        "    # Adjust spacing and display\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Display the first batch from validation: ground truth vs prediction\n",
        "display_side_by_side(\n",
        "    \"runs/detect/val/val_batch0_labels.jpg\",\n",
        "    \"runs/detect/val/val_batch0_pred.jpg\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
