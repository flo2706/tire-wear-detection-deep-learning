{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NaBm_4RqFiC"
      },
      "source": [
        "> **Note:** This notebook is intended to be run on **Google Colab**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZjK1FyUqUTc"
      },
      "source": [
        "### I. Load & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "_W7-XePAp3ar",
        "outputId": "9849d594-083d-429d-cd6f-e2087642fe8c"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nQz15ZOrfW7",
        "outputId": "ed5a5ba3-9206-4422-b5c9-5850030b8c41"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvkfVMllqQjP"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image as IPyImage\n",
        "from PIL import Image as PILImage\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O_yR9vK0EMu"
      },
      "source": [
        "### II. Dataset Extraction & Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nJFtf1wqa10",
        "outputId": "33cf9a2a-7ab9-4404-89fc-d4e5615667e7"
      },
      "outputs": [],
      "source": [
        "# path to the zip dataset\n",
        "zip_path = \"Tire Dataset.v2i.yolov8.zip\"\n",
        "\n",
        "# directory where the dataset will be extracted\n",
        "extract_path = \"/content/dataset\"\n",
        "\n",
        "# create the directory if it does not exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# extract all files from the zip archive\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction terminée. Les fichiers ont été extraits dans :\", extract_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqAPn8BeqvVP",
        "outputId": "6b51269d-2aee-4464-d420-6d3346f1a552"
      },
      "outputs": [],
      "source": [
        "# rename the \"valid\" folder to \"val\"\n",
        "os.rename('/content/dataset/valid', '/content/dataset/val')\n",
        "\n",
        "# read the content of a label file\n",
        "with open('/content/dataset/train/labels/1001_png.rf.05300e4f0f2316063d99d0ca39a76ca6.txt') as f:\n",
        "    lines = f.readlines()\n",
        "    print(\"Contenu du fichier :\")\n",
        "    print(lines)\n",
        "\n",
        "# extract class IDs from the label file\n",
        "class_ids = [line.strip().split()[0] for line in lines]\n",
        "\n",
        "# list unique class IDs used\n",
        "unique_ids = sorted(set(class_ids))\n",
        "print(\"\\nClasses utilisées dans ce fichier :\", unique_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hgetecFrES7",
        "outputId": "4b51be7d-fbf1-4ecd-93b4-bcc583199a20"
      },
      "outputs": [],
      "source": [
        "# read and display the content of the Roboflow README file\n",
        "with open('/content/dataset/README.roboflow.txt') as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzVmCeScBFSt"
      },
      "source": [
        "### III. EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGmwjgBeBIei",
        "outputId": "3ca99831-9881-43e6-ba83-cadc3cbf557f"
      },
      "outputs": [],
      "source": [
        "# Base directory containing the YOLO dataset\n",
        "base = \"/content/dataset\"\n",
        "\n",
        "# Dataset splits to analyze\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "# Loop through each split (train/val/test)\n",
        "for split in splits:\n",
        "    # Build the path to the images and labels folders\n",
        "    img_dir = os.path.join(base, split, \"images\")\n",
        "    lbl_dir = os.path.join(base, split, \"labels\")\n",
        "\n",
        "    # Count images only if the directory exists\n",
        "    n_images = len(os.listdir(img_dir)) if os.path.exists(img_dir) else 0\n",
        "\n",
        "    # Count label files only if the directory exists\n",
        "    n_labels = len(os.listdir(lbl_dir)) if os.path.exists(lbl_dir) else 0\n",
        "\n",
        "    # Display a formatted summary for the current split\n",
        "    print(f\"{split.upper()} – Images: {n_images}, Labels: {n_labels}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dFJOj3kBZ5S",
        "outputId": "474f0034-3bdb-4267-9127-2a9553edcfe3"
      },
      "outputs": [],
      "source": [
        "# List to store the resolutions (width, height) of all images\n",
        "resolutions = []\n",
        "\n",
        "# Path to the training images\n",
        "img_dir = \"/content/dataset/train/images\"\n",
        "\n",
        "# Loop through all images in the training folder\n",
        "for img_name in os.listdir(img_dir):\n",
        "    img_path = os.path.join(img_dir, img_name)\n",
        "\n",
        "    # Open the image using PIL and retrieve its resolution\n",
        "    with PILImage.open(img_path) as img:\n",
        "        resolutions.append(img.size)  # (width, height)\n",
        "\n",
        "# Display the first 10 resolutions and the number of unique resolutions\n",
        "resolutions[:10], f\"Unique resolutions: {len(set(resolutions))}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihHm_NZbCKja"
      },
      "source": [
        "Toutes les images du jeu d’entraînement présentent une résolution unique de 640 × 640 pixels.\n",
        "Signification:\n",
        "- uniformisation du dataset avant publication sur Roboflow\n",
        "- pas de redimensionnement complexe ou de padding supplémentaire\n",
        "- entraînement plus stable et cohérent, car toutes les images ont exactement les mêmes dimensions\n",
        "\n",
        "Conclusion :\n",
        "- résolution homogène\n",
        "- aucun outlier\n",
        "- dataset propre et optimisé pour YOLOv8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIKvQvBlBe9g",
        "outputId": "b66d159a-4e0d-49da-e8dd-a43bd8d1086e"
      },
      "outputs": [],
      "source": [
        "label_files = glob.glob(\"/content/dataset/train/labels/*.txt\")\n",
        "\n",
        "# Dictionary to store how many annotations exist for each class ID\n",
        "class_counts = {}\n",
        "\n",
        "# Loop through all label files in the training set\n",
        "for lf in label_files:\n",
        "    with open(lf) as f:\n",
        "        # Each line corresponds to one bounding box\n",
        "        for line in f:\n",
        "            cls_id = line.split()[0]          # class ID is the first element of each line\n",
        "            # Increment the count for this class\n",
        "            class_counts[cls_id] = class_counts.get(cls_id, 0) + 1\n",
        "\n",
        "# Display the total number of annotations per class\n",
        "class_counts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBczkJ7ECmBd"
      },
      "source": [
        "- Le dataset contient 5285 instances de la seule classe “car-tire\" (pas de déséquilibre)\n",
        "- Volume d’annotations suffisant pour entraîner efficacement un modèle léger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "D6CHyFhFBkIK",
        "outputId": "494f3b78-9afa-44ee-a29b-691f9b040578"
      },
      "outputs": [],
      "source": [
        "def show_bbox(img_path, label_path):\n",
        "    # Load the image as a NumPy array\n",
        "    img = np.array(PILImage.open(img_path))\n",
        "\n",
        "    # Image height and width\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "    # Read YOLO label file (each line contains one bounding box)\n",
        "    with open(label_path) as f:\n",
        "        labels = f.readlines()\n",
        "\n",
        "    # Display the image\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(img)\n",
        "\n",
        "    # Draw each bounding box\n",
        "    for line in labels:\n",
        "        cls, x, y, bw, bh = map(float, line.split())\n",
        "\n",
        "        # Convert YOLO normalized coordinates to pixel values\n",
        "        x1 = int((x - bw/2) * w)\n",
        "        y1 = int((y - bh/2) * h)\n",
        "        x2 = int((x + bw/2) * w)\n",
        "        y2 = int((y + bh/2) * h)\n",
        "\n",
        "        # Draw rectangle around detected object\n",
        "        plt.gca().add_patch(\n",
        "            plt.Rectangle(\n",
        "                (x1, y1),         # top-left corner\n",
        "                x2 - x1,          # width\n",
        "                y2 - y1,          # height\n",
        "                edgecolor=\"red\",  # bounding box color\n",
        "                facecolor=\"none\",\n",
        "                linewidth=2\n",
        "            )\n",
        "        )\n",
        "\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Test the function on a random image\n",
        "\n",
        "img_dir = \"/content/dataset/train/images\"\n",
        "label_dir = \"/content/dataset/train/labels\"\n",
        "\n",
        "# Pick a random image from the training folder\n",
        "sample = random.choice(os.listdir(img_dir))\n",
        "\n",
        "# Display image with its corresponding bounding boxes\n",
        "show_bbox(\n",
        "    os.path.join(img_dir, sample),\n",
        "    os.path.join(label_dir, sample.replace(\".jpg\", \".txt\"))\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e04xY9zi0q2Z"
      },
      "source": [
        "### IV. YAML Configuration File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDlHvllbrGWh"
      },
      "outputs": [],
      "source": [
        "# create and write the corrected YAML configuration file\n",
        "fixed_yaml = \"\"\"\n",
        "train: ../train/images\n",
        "val: ../val/images\n",
        "test: ../test/images\n",
        "\n",
        "nc: 1\n",
        "names: ['car-tire']\n",
        "\n",
        "roboflow:\n",
        "  workspace: iotml\n",
        "  project: tire-dataset\n",
        "  version: 2\n",
        "  license: Public Domain\n",
        "  url: https://universe.roboflow.com/iotml/tire-dataset/dataset/2\n",
        "\"\"\"\n",
        "\n",
        "# save the YAML file to the dataset directory\n",
        "with open('/content/dataset/data.yaml', 'w') as f:\n",
        "    f.write(fixed_yaml)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0gKDNvW7LLv"
      },
      "source": [
        "### V. Model Training & Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCEqTvPRrvQh",
        "outputId": "62cdd46f-fe66-468c-c781-31b5b681d30d"
      },
      "outputs": [],
      "source": [
        "# load the YOLOv8 nano model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# train on the training set and evaluate on the validation set defined in data.yaml\n",
        "model.train(data=\"/content/dataset/data.yaml\", epochs=50, imgsz=640)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        },
        "id": "xPpCyDG5r_Bz",
        "outputId": "d366c6a9-d25f-413e-c500-e344ff89c223"
      },
      "outputs": [],
      "source": [
        "# display the confusion matrix image from the training results\n",
        "IPyImage(filename='runs/detect/train/confusion_matrix.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v9L-h6I7sNHD",
        "outputId": "23808500-90ff-4033-ca8a-a8d9c67529fb"
      },
      "outputs": [],
      "source": [
        "# display an image with a fixed width\n",
        "def display_image(path, width=800):\n",
        "    img = PILImage.open(path)\n",
        "    display(img.resize((width, int(img.height * width / img.width))))\n",
        "\n",
        "# display the main training result plots (reduced size)\n",
        "display_image('runs/detect/train/results.png')\n",
        "display_image('runs/detect/train/BoxPR_curve.png')\n",
        "display_image('runs/detect/train/BoxF1_curve.png')\n",
        "display_image('runs/detect/train/BoxP_curve.png')\n",
        "display_image('runs/detect/train/BoxR_curve.png')\n",
        "display_image('runs/detect/train/confusion_matrix.png')\n",
        "display_image('runs/detect/train/labels.jpg')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iBUsjPm3zPr"
      },
      "source": [
        "- Le modèle YOLOv8n présente d’excellentes performances de détection, avec un mAP50 proche de 95%\n",
        "- Les métriques de précision et de rappel (~91% chacune) indiquent que le modèle détecte les objets de manière fiable, avec peu de faux positifs et peu de faux négatifs. \n",
        "- Le score F1 maximal atteint environ 0.91 à un seuil de confiance optimal d’environ 0.34, ce qui représente le meilleur compromis entre précision et rappel.\n",
        "\n",
        "Le mAP50-95 (~64%) montre une localisation correcte des bounding boxes, même si elle peut être optimisée davantage en utilisant un modèle plus grand, comme YOLOv8m, pour améliorer la précision des détections aux seuils d’IoU plus stricts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDpV2LC68OOj"
      },
      "source": [
        "### VI. Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PiHEsJ4sTeL",
        "outputId": "c429f7eb-25d1-42aa-9b46-ee6a8c8289a6"
      },
      "outputs": [],
      "source": [
        "# load the trained YOLO model\n",
        "trained_model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
        "\n",
        "# evaluate the trained model using the test split\n",
        "metrics = trained_model.val(data=\"/content/dataset/data.yaml\", split=\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvyqgSdZ4Nu_"
      },
      "source": [
        "- Le modèle obtient de très bonnes performances sur le jeu de test, avec un mAP50 de 92.6% et un F1-score élevé (liés à une précision de 87.6% et un rappel de 89.6%).\n",
        "- Le modèle détecte les pneus de manière fiable, avec un très bon équilibre entre faux positifs et faux négatifs\n",
        "- Le mAP50-95 (61.3%) suggère que la localisation des boîtes est correcte mais pourrait être améliorée avec un modèle plus grand comme YOLOv8m."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RvF5dfHBseEn",
        "outputId": "e21185c0-7541-40ef-ab05-84230abbbb07"
      },
      "outputs": [],
      "source": [
        "# display a validation/test image with a fixed width\n",
        "def display_image_val(path, width=500):\n",
        "    img = PILImage.open(path)\n",
        "    display(img.resize((width, int(img.height * width / img.width))))\n",
        "\n",
        "# display evaluation performance plots\n",
        "display_image_val(\"runs/detect/val/BoxF1_curve.png\")\n",
        "display_image_val(\"runs/detect/val/BoxPR_curve.png\")\n",
        "display_image_val(\"runs/detect/val/BoxP_curve.png\")\n",
        "display_image_val(\"runs/detect/val/BoxR_curve.png\")\n",
        "display_image_val(\"runs/detect/val/confusion_matrix.png\")\n",
        "\n",
        "# display an example of prediction vs ground truth\n",
        "display_image_val(\"runs/detect/val/val_batch0_labels.jpg\")  # ground truth\n",
        "display_image_val(\"runs/detect/val/val_batch0_pred.jpg\")    # model predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUdBhHqH48lR"
      },
      "source": [
        "- F1 ≈ 0.89 : très bon équilibre précision/rappel\n",
        "- Seuil optimal ≈ 0.17 : le modèle a tendance à être performant même en gardant des prédictions de faible confiance\n",
        "- mAP50 très élevé (0.926) : le modèle détecte très bien la présence de l’objet\n",
        "- mAP50-95 plus faible (0.613) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h94BXDyl9Uuu"
      },
      "source": [
        "### VII. Qualitative Evaluation (Visual Comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "g4MO1YHys7W_",
        "outputId": "cd0474c2-7cd8-4524-eaef-dc8be416d16f"
      },
      "outputs": [],
      "source": [
        "# display two images side by side for comparison\n",
        "def display_side_by_side(img1_path, img2_path, label1=\"Ground Truth\", label2=\"Prediction\"):\n",
        "    img1 = PILImage.open(img1_path)\n",
        "    img2 = PILImage.open(img2_path)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(14, 7))\n",
        "\n",
        "    axs[0].imshow(img1)\n",
        "    axs[0].set_title(label1, fontsize=14)\n",
        "    axs[0].axis(\"off\")\n",
        "\n",
        "    axs[1].imshow(img2)\n",
        "    axs[1].set_title(label2, fontsize=14)\n",
        "    axs[1].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# test with batch 0\n",
        "display_side_by_side(\n",
        "    \"runs/detect/val/val_batch0_labels.jpg\",\n",
        "    \"runs/detect/val/val_batch0_pred.jpg\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAmPnT7x9b0K"
      },
      "source": [
        "### VIII. Inference on New Images (Real-World Testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lxc1Ja1btZTH",
        "outputId": "8ccec034-445e-4036-f6bc-9391e998ad49"
      },
      "outputs": [],
      "source": [
        "# run inference on an image and save the predictions\n",
        "results = trained_model.predict(\n",
        "    source=\"/content/auto9.jpg\",\n",
        "    conf=0.239,\n",
        "    save=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        },
        "id": "SUl3RwZhtgCD",
        "outputId": "e5762962-2edb-4f6c-8d2c-1af83dae415a"
      },
      "outputs": [],
      "source": [
        "display(PILImage.open(\"runs/detect/predict/auto1.jpg\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h7iX2ogJtjqx",
        "outputId": "5471b77b-2635-4b14-9b64-5c67459bee27"
      },
      "outputs": [],
      "source": [
        "results_2 = trained_model.predict(source=\"/content/auto2.jpg\", conf=0.239, save=True)\n",
        "display(PILImage.open(\"runs/detect/predict/auto2.jpg\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ec6LitXatv1a",
        "outputId": "087597bd-b4d1-403b-a7ea-5ac2d56ad45e"
      },
      "outputs": [],
      "source": [
        "results_3 = trained_model.predict(source=\"/content/auto3.jpg\", conf=0.239, save=True)\n",
        "display(PILImage.open(\"runs/detect/predict/auto3.jpg\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "omVbKHt1t10t",
        "outputId": "1d05b9af-c87c-4619-91e4-3c9abce3e08d"
      },
      "outputs": [],
      "source": [
        "results_4 = trained_model.predict(source=\"/content/auto4.jpg\", conf=0.239, save=True)\n",
        "display(PILImage.open(\"runs/detect/predict/auto4.jpg\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HL1RX5qpt8kd",
        "outputId": "1ff3d0ac-c6c7-4bcc-d041-c5b50fe69d31"
      },
      "outputs": [],
      "source": [
        "results_5 = trained_model.predict(source=\"/content/auto5.jpg\", conf=0.239, save=True)\n",
        "display(PILImage.open(\"runs/detect/predict/auto5.jpg\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "9hkYyV3xuBYj",
        "outputId": "d7dbdd4e-0823-4282-880b-97c566cb1419"
      },
      "outputs": [],
      "source": [
        "results_6 = trained_model.predict(source=\"/content/auto6.jpg\", conf=0.239, save=True)\n",
        "display(PILImage.open(\"runs/detect/predict/auto6.jpg\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "Y57OgSlhuG9w",
        "outputId": "e2405c30-9837-46ca-d6dd-c6b92e85eda3"
      },
      "outputs": [],
      "source": [
        "results_7 = trained_model.predict(source=\"/content/auto7.jpg\", conf=0.239, save=True)\n",
        "display(PILImage.open(\"runs/detect/predict/auto7.jpg\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "QJYsCSJPuNzh",
        "outputId": "c29ff39b-e0a4-45f3-cbfb-a8ae524e1ff4"
      },
      "outputs": [],
      "source": [
        "results_8 = trained_model.predict(source=\"/content/auto9.jpg\", conf=0.239, save=True)\n",
        "display(PILImage.open(\"runs/detect/predict/auto9.jpg\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
